---
title: "p8105_hw6_TS3175"
author: "Tanu"
date: "11/20/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(p8105.datasets)
library(viridis)
library(gridExtra)
library(modelr)
library(mgcv)
library(patchwork)
```

# Problem 1

Loading in dataset, creating factor variables, and checking for missing data

```{r}
bwt_data = read.csv("birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex,    levels= c("1", "2"),
                                 labels = c("male", "female")),
    frace =   factor(frace,      levels= c("1", "2", "3", "4", "8", "9"),
                                 labels = c("white", "black","asian", "puerto rican", "other", "uknown")),
    malform = factor(malform,    levels= c("0", "1"),
                                 labels = c("absent", "present")),
    mrace = factor(mrace,        levels= c("1", "2", "3", "4", "8", "9"),
                                 labels = c("white", "black","asian", "puerto rican", "other", "uknown"))
  )

  skimr::skim(bwt_data)
```

Created a model for birthweight based on mother's age and family income because these are factors noted in the literature as associated with stress and ultimately baby health. Then plotted residuals against fitted values.

```{r}
model = lm(bwt ~ momage + fincome, data = bwt_data) 
model %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

  modelr::add_residuals(bwt_data,model) %>% 
  modelr::add_predictions(model) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point()

```

Made comparisons of the following models in terms of the cross-validated prediction error using crossv_mc and functions in purrr.

```{r}
model1= lm(bwt ~ blength + gaweeks, data=bwt_data) 
model1 %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)

model2= lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + babysex*blength*bhead, data=bwt_data)

model2 %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 3)
```

```{r}
cv_df =
  crossv_mc(bwt_data, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```

```{r}
cv_df=
 cv_df %>% 
  mutate(model  = map(train, ~lm(bwt ~ momage + fincome, data = .x)),
   model1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
   model2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = as_tibble(.x)))) %>% 
  mutate(rmse_model = map2_dbl(model, test, ~rmse(model = .x, data = .y)),
  rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
  rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)))
```

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```


Model 2 appears to be the best model.

# Problem 2

```{r message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


Used 5000 bootstrap samples and, for each bootstrap sample, produced estimates of these two quantities. Then, I plotted the distribution of my estimates.

```{r}
samples = weather_df %>% modelr::bootstrap(n = 500) %>% 
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy),
    glance = map(models, broom::glance)) %>% 
  select(results, glance, .id) %>% 
  unnest(results) %>% 
  pivot_wider( 
    names_from = term,
    values_from = c(estimate, std.error, glance),
    id_cols = .id, 
    ) %>%
  janitor::clean_names() %>%
  unnest(c(glance_intercept), .names_repair = "universal") %>% 
  mutate(
    log_b0_b1 = log(estimate_intercept * estimate_tmin)
  )  
```

```{r}
rsq = samples %>% 
  ggplot(aes(x = r.squared)) + 
  geom_density() + 
  theme_minimal() 
betas = samples %>% 
  ggplot(aes(x = log_b0_b1)) + 
  geom_density() + 
  theme_minimal() 

rsq + betas
```

The plots above appear to be normally distributed and unimodal. The r squared distribution has a median of approximately 0.915 while the log_b0_b1 has a median of approximately 2.015. 


Then, I used the 5000 bootstrap estimates, identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for r̂ 2 and log(β̂ 0∗β̂ 1).

```{r}
samples %>% 
  pull(r.squared) %>% 
  quantile(c(0.025, 0.975)) %>% 
  knitr::kable(col.names = "R-Squared")
samples %>% 
  pull(log_b0_b1) %>% 
  quantile(c(0.025, 0.975)) %>% 
  knitr::kable(col.names = "Log(B0*B1)")
```